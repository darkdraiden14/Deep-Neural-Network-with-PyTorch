{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "2.1Prediction1Dregression_v3.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darkdraiden14/Deep-Neural-Network-with-PyTorch/blob/master/Prediction%20Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH-RAsjm4tdS",
        "colab_type": "text"
      },
      "source": [
        "<h1>Linear Regression 1D: Prediction</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-Q1pn6B4tdU",
        "colab_type": "text"
      },
      "source": [
        "<h2>Preparation</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RoCgdsr4tdU",
        "colab_type": "text"
      },
      "source": [
        "The following are the libraries we are going to use for this lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCFAKlS34tdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# These are the libraries will be used for this lab.\n",
        "\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oba0xdzz4tdc",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOgXLeOl4tdd",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"Prediction\">Prediction</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sprHa9s4tdf",
        "colab_type": "text"
      },
      "source": [
        "Let us create the following expressions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH1Xdq9K4tdg",
        "colab_type": "text"
      },
      "source": [
        "$b=-1,w=2$\n",
        "\n",
        "$\\hat{y}=-1+2x$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0OFqXAl4tdh",
        "colab_type": "text"
      },
      "source": [
        "First, define the parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkfX5M_D4tdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define w = 2 and b = -1 for y = wx + b\n",
        "\n",
        "w = torch.tensor(2.0, requires_grad = True)\n",
        "b = torch.tensor(-1.0, requires_grad = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS2-uKlQ4tdn",
        "colab_type": "text"
      },
      "source": [
        "Then, define the function <code>forward(x, w, b)</code> makes the prediction: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsHu78kJ4tdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function forward(x) for prediction\n",
        "\n",
        "def forward(x):\n",
        "    yhat = w * x + b\n",
        "    return yhat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oExJinKR4tdt",
        "colab_type": "text"
      },
      "source": [
        "Let's make the following prediction at <i>x = 1</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnAW0LSu4tdu",
        "colab_type": "text"
      },
      "source": [
        "$\\hat{y}=-1+2x$\n",
        "\n",
        "$\\hat{y}=-1+2(1)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cfJv7MO4tdw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e960c45b-e547-423a-fa02-28861d3f967a"
      },
      "source": [
        "# Predict y = 2x - 1 at x = 1\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "yhat = forward(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[1.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p98rmUA4td0",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU65NFla4td2",
        "colab_type": "text"
      },
      "source": [
        "Now, let us try to make the prediction for multiple inputs:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbsJAFZe4td3",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter2/2.1.2.png\" width=\"500\" alt=\"Linear Regression Multiple Input Samples\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TKcMIfY4td4",
        "colab_type": "text"
      },
      "source": [
        "Let us construct the <code>x</code> tensor first. Check the shape of <code>x</code>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC1se9za4td5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0270e55-8383-47ea-cb45-7c1087c9046e"
      },
      "source": [
        "# Create x Tensor and check the shape of x tensor\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0]])\n",
        "print(\"The shape of x: \", x.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of x:  torch.Size([2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTPM7edS4td-",
        "colab_type": "text"
      },
      "source": [
        "Now make the prediction: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0jhGix64td_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8fcf0938-9d8f-4317-d1dc-e63d7f6cfa08"
      },
      "source": [
        "# Make the prediction of y = 2x - 1 at x = [1, 2]\n",
        "\n",
        "yhat = forward(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[1.],\n",
            "        [3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD2NIk8n4teD",
        "colab_type": "text"
      },
      "source": [
        "The result is the same as what it is in the image above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvu4a_-w4teE",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30ZKv5cB4teF",
        "colab_type": "text"
      },
      "source": [
        "<h3>Practice</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTfMFyhF4teG",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction of the following <code>x</code> tensor using the <code>w</code> and <code>b</code> from above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6EaZ0yI4teG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5ba5700b-7e9a-4ca0-fb27-e20c0be96fe0"
      },
      "source": [
        "# Practice: Make a prediction of y = 2x - 1 at x = [[1.0], [2.0], [3.0]]\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
        "yhat = forward(x)\n",
        "print(\"Prediction is : \",yhat)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction is :  tensor([[1.],\n",
            "        [3.],\n",
            "        [5.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c9JL4sn4teO",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km7duouz4teP",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"Linear\">Class Linear</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWw_vT1k4teQ",
        "colab_type": "text"
      },
      "source": [
        "The linear class can be used to make a prediction. We can also use the linear class to build more complex models. Let's import the module:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_huWW1Rq4teR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Class Linear\n",
        "\n",
        "from torch.nn import Linear"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPD-Q5Ur4teV",
        "colab_type": "text"
      },
      "source": [
        "Set the random seed because the parameters are randomly initialized:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJJ3iucR4teW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "664cb61b-5e47-4e4f-d05d-f35957705b43"
      },
      "source": [
        "# Set random seed\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fda1b1c3590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO4IBM854tea",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fNc2Vuy4teb",
        "colab_type": "text"
      },
      "source": [
        "Let us create the linear object by using the constructor. The parameters are randomly created. Let us print out to see what <i>w</i> and <i>b</i>. The parameters of an <code>torch.nn.Module</code> model are contained in the modelâ€™s parameters accessed with <code>lr.parameters()</code>:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHv-t6fX4tec",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "11c74bcb-9dc0-4eee-ca1f-9e629bee5c3c"
      },
      "source": [
        "# Create Linear Regression Model, and print out the parameters\n",
        "\n",
        "lr = Linear(in_features=1, out_features=1, bias=True)\n",
        "print(\"Parameters w and b: \", list(lr.parameters()))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters w and b:  [Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt8NyACV4tei",
        "colab_type": "text"
      },
      "source": [
        "This is equivalent to the following expression:  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcnCRpZU4tej",
        "colab_type": "text"
      },
      "source": [
        "$b=-0.44, w=0.5153$\n",
        "\n",
        "$\\hat{y}=-0.44+0.5153x$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7Bm7W0R4tek",
        "colab_type": "text"
      },
      "source": [
        "A method  <code>state_dict()</code> Returns a Python dictionary object corresponding to the layers of each parameter  tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAZgusCS4tel",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a974a4cc-d809-44b0-8fdf-18b21a743ba4"
      },
      "source": [
        "print(\"Python dictionary: \",lr.state_dict())\n",
        "print(\"keys: \",lr.state_dict().keys())\n",
        "print(\"values: \",lr.state_dict().values())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python dictionary:  OrderedDict([('weight', tensor([[0.5153]])), ('bias', tensor([-0.4414]))])\n",
            "keys:  odict_keys(['weight', 'bias'])\n",
            "values:  odict_values([tensor([[0.5153]]), tensor([-0.4414])])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9DMxMcW4tep",
        "colab_type": "text"
      },
      "source": [
        "The keys correspond to the name of the attributes and the values correspond to the parameter value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJEFDbDk4tep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0b4ea3ce-3891-414f-bf8c-bd5d16834d66"
      },
      "source": [
        "print(\"weight:\",lr.weight)\n",
        "print(\"bias:\",lr.bias)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight: Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True)\n",
            "bias: Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-kPjSk74tes",
        "colab_type": "text"
      },
      "source": [
        "Now let us make a single prediction at <i>x = [[1.0]]</i>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK2osLrY4teu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9912a95-9497-43e3-ef3d-c0e1a55657eb"
      },
      "source": [
        "# Make the prediction at x = [[1.0]]\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.0739]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-weRbdt4tey",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwUwR6gg4tez",
        "colab_type": "text"
      },
      "source": [
        "Similarly, you can make multiple predictions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqPYtihB4te0",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter2/2.1.2vector_function.png\" width=\"500\" alt=\"Linear Class Sample with Multiple Inputs\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T3_EFKl4te0",
        "colab_type": "text"
      },
      "source": [
        "Use model <code>lr(x)</code> to predict the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi8QWmnn4te1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4d3897a5-6d7c-402a-f8eb-14c538f49671"
      },
      "source": [
        "# Create the prediction using linear model\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.0739],\n",
            "        [0.5891]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GypO9jNX4te4",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn0vhWRK4te5",
        "colab_type": "text"
      },
      "source": [
        "<h3>Practice</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmSiP2R54te6",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction of the following <code>x</code> tensor using the linear regression model <code>lr</code>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOk4CeQ14te6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "eca08c07-6cd4-4c7f-e071-249f27ce719f"
      },
      "source": [
        "# Practice: Use the linear regression model object lr to make the prediction.\n",
        "\n",
        "x = torch.tensor([[1.0],[2.0],[3.0]])\n",
        "yhat = lr(x)\n",
        "print(\"Prediction : \",yhat)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction :  tensor([[0.0739],\n",
            "        [0.5891],\n",
            "        [1.1044]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKvxxf1B4te_",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXhwFe9O4tfA",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"Cust\">Build Custom Modules</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX7_NMOS4tfC",
        "colab_type": "text"
      },
      "source": [
        "Now, let's build a custom module. We can make more complex models by using this method later on. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sTX2kJJ4tfE",
        "colab_type": "text"
      },
      "source": [
        "First, import the following library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dft74yGI4tfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Library for this section\n",
        "\n",
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB-wMr4p4tfI",
        "colab_type": "text"
      },
      "source": [
        "Now, let us define the class: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvtVE7t74tfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Customize Linear Regression Class\n",
        "\n",
        "class LR(nn.Module):\n",
        "    \n",
        "    # Constructor\n",
        "    def __init__(self, input_size, output_size):\n",
        "        \n",
        "        # Inherit from parent\n",
        "        super(LR, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)\n",
        "    \n",
        "    # Prediction function\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDhVPTzH4tfM",
        "colab_type": "text"
      },
      "source": [
        "Create an object by using the constructor. Print out the parameters we get and the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSKTFYww4tfN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "354ccf2d-ee2b-4634-ca6c-5a2709d85e88"
      },
      "source": [
        "# Create the linear regression model. Print out the parameters.\n",
        "\n",
        "lr = LR(1, 1)\n",
        "print(\"The parameters: \", list(lr.parameters()))\n",
        "print(\"Linear model: \", lr.linear)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters:  [Parameter containing:\n",
            "tensor([[-0.1939]], requires_grad=True), Parameter containing:\n",
            "tensor([0.4694], requires_grad=True)]\n",
            "Linear model:  Linear(in_features=1, out_features=1, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vkEXPCh4tfR",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5VULXX44tfS",
        "colab_type": "text"
      },
      "source": [
        "Let us try to make a prediction of a single input sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_jFDAm84tfT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ed9ba79-6358-413c-b718-fdbefa398de7"
      },
      "source": [
        "# Try our customize linear regression model with single input\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.2755]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caTqMkWn4tfY",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esCWWJmd4tfY",
        "colab_type": "text"
      },
      "source": [
        "Now, let us try another example with multiple samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkI4HmyE4tfZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "58c3a762-03ac-4369-f178-5ca2d56de3a1"
      },
      "source": [
        "# Try our customize linear regression model with multiple input\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.2755],\n",
            "        [0.0816]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsZYCZmH4tfd",
        "colab_type": "text"
      },
      "source": [
        "the parameters are also stored in an ordered dictionary :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaAlxhWO4tfd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3bad3fa1-16a9-4979-9aad-9115fefd1375"
      },
      "source": [
        "print(\"Python dictionary: \", lr.state_dict())\n",
        "print(\"keys: \",lr.state_dict().keys())\n",
        "print(\"values: \",lr.state_dict().values())\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python dictionary:  OrderedDict([('linear.weight', tensor([[-0.1939]])), ('linear.bias', tensor([0.4694]))])\n",
            "keys:  odict_keys(['linear.weight', 'linear.bias'])\n",
            "values:  odict_values([tensor([[-0.1939]]), tensor([0.4694])])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcngWPO34tfh",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRuCtMVv4tfi",
        "colab_type": "text"
      },
      "source": [
        "<h3>Practice</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QcnRciG4tfj",
        "colab_type": "text"
      },
      "source": [
        "Create an object <code>lr1</code> from the class we created before and make a prediction by using the following tensor: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLaet8mr4tfk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1407e198-d7fe-45c8-fa02-8b4cdd4b23b7"
      },
      "source": [
        "# Practice: Use the LR class to create a model and make a prediction of the following tensor.\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
        "yhat = lr(x)\n",
        "print(\" The Prediction : \",yhat)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " The Prediction :  tensor([[ 0.2755],\n",
            "        [ 0.0816],\n",
            "        [-0.1122]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L2e4xiw4tfp",
        "colab_type": "text"
      },
      "source": [
        "<hr>"
      ]
    }
  ]
}