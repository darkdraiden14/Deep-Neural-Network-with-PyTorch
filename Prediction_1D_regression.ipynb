{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Prediction 1D regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darkdraiden14/Deep-Neural-Network-with-PyTorch/blob/master/Prediction_1D_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-5qhDvNSoqS",
        "colab_type": "text"
      },
      "source": [
        "<h1>Linear Regression 1D: Prediction</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMPAoTX7SoqV",
        "colab_type": "text"
      },
      "source": [
        "<h2>Preparation</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnyp0syaSoqX",
        "colab_type": "text"
      },
      "source": [
        "The following are the libraries we are going to use for this lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HA1Ib3VSoqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# These are the libraries will be used for this lab.\n",
        "\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFme719ESoqd",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"Prediction\">Prediction</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMVfbgEUSoqe",
        "colab_type": "text"
      },
      "source": [
        "Let us create the following expressions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AHldthRSoqf",
        "colab_type": "text"
      },
      "source": [
        "$b=-1,w=2$\n",
        "\n",
        "$\\hat{y}=-1+2x$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k0Nu9koSoqg",
        "colab_type": "text"
      },
      "source": [
        "First, define the parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a7Pc2W_Soqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define w = 2 and b = -1 for y = wx + b\n",
        "\n",
        "w = torch.tensor(2.0, requires_grad = True)\n",
        "b = torch.tensor(-1.0, requires_grad = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPaW68oSSoql",
        "colab_type": "text"
      },
      "source": [
        "Then, define the function <code>forward(x, w, b)</code> makes the prediction: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxYrfoYfSoqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function forward(x) for prediction\n",
        "\n",
        "def forward(x):\n",
        "    yhat = w * x + b\n",
        "    return yhat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGxobGNiSoqq",
        "colab_type": "text"
      },
      "source": [
        "Let's make the following prediction at <i>x = 1</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DokTOHvdSoqr",
        "colab_type": "text"
      },
      "source": [
        "$\\hat{y}=-1+2x$\n",
        "\n",
        "$\\hat{y}=-1+2(1)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KhU0XteSoqs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a5cca9e-08ad-4ccd-a762-4287d7af6f1c"
      },
      "source": [
        "# Predict y = 2x - 1 at x = 1\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "yhat = forward(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[1.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCahkNA8Soqx",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm-_P26OSoqx",
        "colab_type": "text"
      },
      "source": [
        "Now, let us try to make the prediction for multiple inputs:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhfcWGrFSoqy",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter2/2.1.2.png\" width=\"500\" alt=\"Linear Regression Multiple Input Samples\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8EP_Bp8Soqz",
        "colab_type": "text"
      },
      "source": [
        "Let us construct the <code>x</code> tensor first. Check the shape of <code>x</code>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwcK7rmQSoq0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3dc07895-c1ff-423b-ddd8-f1f7b938d72c"
      },
      "source": [
        "# Create x Tensor and check the shape of x tensor\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0]])\n",
        "print(\"The shape of x: \", x.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of x:  torch.Size([2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43N9TlH5Soq4",
        "colab_type": "text"
      },
      "source": [
        "Now make the prediction: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhWN--qiSoq5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6c9fd00b-e600-43d8-9f69-448aa3415410"
      },
      "source": [
        "# Make the prediction of y = 2x - 1 at x = [1, 2]\n",
        "\n",
        "yhat = forward(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[1.],\n",
            "        [3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBZnFntvSoq9",
        "colab_type": "text"
      },
      "source": [
        "The result is the same as what it is in the image above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61bS7kMMSoq-",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy83ekLoSoq_",
        "colab_type": "text"
      },
      "source": [
        "<h3>Practice</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgK3qfGLSorA",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction of the following <code>x</code> tensor using the <code>w</code> and <code>b</code> from above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSSRQtq7SorA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "afeda7b5-9145-45a6-d466-a507b02d6b4a"
      },
      "source": [
        "# Practice: Make a prediction of y = 2x - 1 at x = [[1.0], [2.0], [3.0]]\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
        "yhat = forward(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[1.],\n",
            "        [3.],\n",
            "        [5.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XJPo5uySorG",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRZyC17vSorG",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"Linear\">Class Linear</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55CEaALjSorH",
        "colab_type": "text"
      },
      "source": [
        "The linear class can be used to make a prediction. We can also use the linear class to build more complex models. Let's import the module:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsOyBhTYSorI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Class Linear\n",
        "\n",
        "from torch.nn import Linear"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqfmtWGlSorM",
        "colab_type": "text"
      },
      "source": [
        "Set the random seed because the parameters are randomly initialized:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djYihLRESorN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e352539-d261-44e3-bff3-b9113f4b0693"
      },
      "source": [
        "# Set random seed\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f6c6dce0190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saLIdqM8SorQ",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFccvBJ-SorS",
        "colab_type": "text"
      },
      "source": [
        "Let us create the linear object by using the constructor. The parameters are randomly created. Let us print out to see what <i>w</i> and <i>b</i>. The parameters of an <code>torch.nn.Module</code> model are contained in the model’s parameters accessed with <code>lr.parameters()</code>:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQhP42GOSorS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d7df44f7-74dc-4616-a0ab-289b550e1e38"
      },
      "source": [
        "# Create Linear Regression Model, and print out the parameters\n",
        "\n",
        "lr = Linear(in_features=1, out_features=1, bias=True)\n",
        "print(\"Parameters w and b: \", list(lr.parameters()))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters w and b:  [Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk-bXj0iSorX",
        "colab_type": "text"
      },
      "source": [
        "This is equivalent to the following expression:  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUpYWx_ySorZ",
        "colab_type": "text"
      },
      "source": [
        "$b=-0.44, w=0.5153$\n",
        "\n",
        "$\\hat{y}=-0.44+0.5153x$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpXLok12SorZ",
        "colab_type": "text"
      },
      "source": [
        "A method  <code>state_dict()</code> Returns a Python dictionary object corresponding to the layers of each parameter  tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsvgW3cwSora",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a8a00233-811d-4b78-a147-754612b22b9a"
      },
      "source": [
        "print(\"Python dictionary: \",lr.state_dict())\n",
        "print(\"keys: \",lr.state_dict().keys())\n",
        "print(\"values: \",lr.state_dict().values())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python dictionary:  OrderedDict([('weight', tensor([[0.5153]])), ('bias', tensor([-0.4414]))])\n",
            "keys:  odict_keys(['weight', 'bias'])\n",
            "values:  odict_values([tensor([[0.5153]]), tensor([-0.4414])])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWX8pFLCSore",
        "colab_type": "text"
      },
      "source": [
        "The keys correspond to the name of the attributes and the values correspond to the parameter value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQVM0yvaSore",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b77af0de-f5bd-49fe-ba2d-18090cf7e876"
      },
      "source": [
        "print(\"weight:\",lr.weight)\n",
        "print(\"bias:\",lr.bias)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight: Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True)\n",
            "bias: Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTLsRLLISorh",
        "colab_type": "text"
      },
      "source": [
        "Now let us make a single prediction at <i>x = [[1.0]]</i>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCiUPb5-Sori",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e0ae7ac-4e3c-41d7-de68-df47542d0405"
      },
      "source": [
        "# Make the prediction at x = [[1.0]]\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.0739]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sre389RHSorl",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee0PsNGcSorl",
        "colab_type": "text"
      },
      "source": [
        "Similarly, you can make multiple predictions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRLCF02cSorm",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter2/2.1.2vector_function.png\" width=\"500\" alt=\"Linear Class Sample with Multiple Inputs\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1z7erXQSorm",
        "colab_type": "text"
      },
      "source": [
        "Use model <code>lr(x)</code> to predict the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbGFfZkISorn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6feafb3f-99cb-4dc6-f44a-02c3d5895d4d"
      },
      "source": [
        "# Create the prediction using linear model\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.0739],\n",
            "        [0.5891]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxUhPu3HSorq",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErEf6mZbSorr",
        "colab_type": "text"
      },
      "source": [
        "<h3>Practice</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vyn8h46RSors",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction of the following <code>x</code> tensor using the linear regression model <code>lr</code>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziOp60CuSors",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "25ae7b7d-d690-4e81-ee8f-1f49ff8ef0f8"
      },
      "source": [
        "# Practice: Use the linear regression model object lr to make the prediction.\n",
        "\n",
        "x = torch.tensor([[1.0],[2.0],[3.0]])\n",
        "x=torch.tensor([[1.0],[2.0],[3.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.0739],\n",
            "        [0.5891],\n",
            "        [1.1044]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TQNnP9SSorw",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXWajarcSorx",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"Cust\">Build Custom Modules</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RNRk5H2Sory",
        "colab_type": "text"
      },
      "source": [
        "Now, let's build a custom module. We can make more complex models by using this method later on. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt4qrRj4Sorz",
        "colab_type": "text"
      },
      "source": [
        "First, import the following library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS1raUfoSor0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Library for this section\n",
        "\n",
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMAvRb6mSor5",
        "colab_type": "text"
      },
      "source": [
        "Now, let us define the class: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KokRJpdcSor6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Customize Linear Regression Class\n",
        "\n",
        "class LR(nn.Module):\n",
        "    \n",
        "    # Constructor\n",
        "    def __init__(self, input_size, output_size):\n",
        "        \n",
        "        # Inherit from parent\n",
        "        super(LR, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)\n",
        "    \n",
        "    # Prediction function\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt0VLDI6Sor-",
        "colab_type": "text"
      },
      "source": [
        "Create an object by using the constructor. Print out the parameters we get and the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6QscTROSor_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9e7a0588-5713-4569-f913-87d57c2de392"
      },
      "source": [
        "# Create the linear regression model. Print out the parameters.\n",
        "\n",
        "lr = LR(1, 1)\n",
        "print(\"The parameters: \", list(lr.parameters()))\n",
        "print(\"Linear model: \", lr.linear)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters:  [Parameter containing:\n",
            "tensor([[-0.1939]], requires_grad=True), Parameter containing:\n",
            "tensor([0.4694], requires_grad=True)]\n",
            "Linear model:  Linear(in_features=1, out_features=1, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq-_2b5jSosC",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iEawxpASosC",
        "colab_type": "text"
      },
      "source": [
        "Let us try to make a prediction of a single input sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us8gkgP9SosD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1fb9b264-2017-4447-991a-5c1f9c406f17"
      },
      "source": [
        "# Try our customize linear regression model with single input\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.2755]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7eyD-SmSosG",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkN8SjLISosG",
        "colab_type": "text"
      },
      "source": [
        "Now, let us try another example with multiple samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvFZWf6zSosH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "40150fe4-1793-42de-e840-642e1b2fa487"
      },
      "source": [
        "# Try our customize linear regression model with multiple input\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.2755],\n",
            "        [0.0816]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh57ULncSosL",
        "colab_type": "text"
      },
      "source": [
        "the parameters are also stored in an ordered dictionary :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9VLi4MASosM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b6d54d4c-8d5b-4f18-fb7c-eac9b1441eb6"
      },
      "source": [
        "print(\"Python dictionary: \", lr.state_dict())\n",
        "print(\"keys: \",lr.state_dict().keys())\n",
        "print(\"values: \",lr.state_dict().values())\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python dictionary:  OrderedDict([('linear.weight', tensor([[-0.1939]])), ('linear.bias', tensor([0.4694]))])\n",
            "keys:  odict_keys(['linear.weight', 'linear.bias'])\n",
            "values:  odict_values([tensor([[-0.1939]]), tensor([0.4694])])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HsxjmkvSosQ",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFUmk9oWSosQ",
        "colab_type": "text"
      },
      "source": [
        "<h3>Practice</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAC1L4adSosR",
        "colab_type": "text"
      },
      "source": [
        "Create an object <code>lr1</code> from the class we created before and make a prediction by using the following tensor: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayvLeGB_SosR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7fa8c196-08bd-4eb7-8f47-5c076c15e191"
      },
      "source": [
        "# Practice: Use the LR class to create a model and make a prediction of the following tensor.\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
        "x=torch.tensor([[1.0],[2.0],[3.0]])\n",
        "lr1=LR(1,1)\n",
        "yhat=lr(x)\n",
        "yhat"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2755],\n",
              "        [ 0.0816],\n",
              "        [-0.1122]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}